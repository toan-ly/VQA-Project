# VQA-Project: Visual Question Answering

This project contains implementation of a Visual Question Answering system, which integrates computer vision and natural langauge processing techniques to answer questions about images.

This project explores various VQA models, including:

- **CNN + LSTM**: Combines Convolutional Neural Networks for image feature extraction with Long Short-Term Memory networks for question processing
- **VIT + RoBERTa**: Utilizes transformer architectures for both visual and textual data to compare complex relationships
- **LLaVA**: Employs large scale pretrained models for enhanced understanding of visual and textual modalities